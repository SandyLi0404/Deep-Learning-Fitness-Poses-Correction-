{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44638ae",
   "metadata": {},
   "source": [
    "# Step 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255a180",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eccd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/qz/Desktop/Computer Vision/Deep-Learning-Fitness-Poses-Correction-/yoga_env/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/qz/Desktop/Computer Vision/Deep-Learning-Fitness-Poses-Correction-/yoga_env/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7e4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary files\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cabf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "\n",
    "angles_path = \"../angles_clean\"\n",
    "\n",
    "RESULTS_DIR = f\"{angles_path}\"\n",
    "POSES = [\"downdog\", \"goddess\", \"plank\", \"tree\", \"warrior2\"]\n",
    "\n",
    "# model save paths\n",
    "models_path = \"../models_new\"\n",
    "\n",
    "MODELS_DIR = f\"{models_path}\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, \"yoga_angle_resnet.pt\")\n",
    "META_PATH  = os.path.join(MODELS_DIR, \"yoga_angle_resnet_meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdc68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 60\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "patience = 10 # for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033cfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all angles loaded shape: (945, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_label</th>\n",
       "      <th>image_path</th>\n",
       "      <th>left_elbow_angle</th>\n",
       "      <th>right_elbow_angle</th>\n",
       "      <th>left_shoulder_angle</th>\n",
       "      <th>right_shoulder_angle</th>\n",
       "      <th>left_knee_angle</th>\n",
       "      <th>right_knee_angle</th>\n",
       "      <th>hand_angle</th>\n",
       "      <th>left_hip_angle</th>\n",
       "      <th>right_hip_angle</th>\n",
       "      <th>neck_angle_uk</th>\n",
       "      <th>left_wrist_angle_bk</th>\n",
       "      <th>right_wrist_angle_bk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>../../data_clean/Downdog/Images/00000372.jpg</td>\n",
       "      <td>195.382277</td>\n",
       "      <td>189.994100</td>\n",
       "      <td>181.919382</td>\n",
       "      <td>180.159746</td>\n",
       "      <td>153.536511</td>\n",
       "      <td>156.576545</td>\n",
       "      <td>1.285724</td>\n",
       "      <td>290.903067</td>\n",
       "      <td>287.620923</td>\n",
       "      <td>247.619865</td>\n",
       "      <td>275.332105</td>\n",
       "      <td>273.613412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>../../data_clean/Downdog/Images/00000414.jpg</td>\n",
       "      <td>161.394529</td>\n",
       "      <td>158.980446</td>\n",
       "      <td>163.869613</td>\n",
       "      <td>198.508847</td>\n",
       "      <td>181.839432</td>\n",
       "      <td>178.438866</td>\n",
       "      <td>358.240615</td>\n",
       "      <td>83.145803</td>\n",
       "      <td>85.550792</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>80.704666</td>\n",
       "      <td>81.109078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>../../data_clean/Downdog/Images/00000158.jpg</td>\n",
       "      <td>188.316559</td>\n",
       "      <td>189.387117</td>\n",
       "      <td>188.434129</td>\n",
       "      <td>168.625045</td>\n",
       "      <td>186.825185</td>\n",
       "      <td>185.690404</td>\n",
       "      <td>342.449527</td>\n",
       "      <td>273.259646</td>\n",
       "      <td>275.749535</td>\n",
       "      <td>335.224859</td>\n",
       "      <td>278.820494</td>\n",
       "      <td>281.517431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>../../data_clean/Downdog/Images/00000164.jpg</td>\n",
       "      <td>163.143669</td>\n",
       "      <td>151.368673</td>\n",
       "      <td>174.269075</td>\n",
       "      <td>190.190288</td>\n",
       "      <td>180.294451</td>\n",
       "      <td>179.480325</td>\n",
       "      <td>29.600620</td>\n",
       "      <td>79.003156</td>\n",
       "      <td>74.516612</td>\n",
       "      <td>13.561052</td>\n",
       "      <td>79.992020</td>\n",
       "      <td>75.961132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>../../data_clean/Downdog/Images/00000170.jpg</td>\n",
       "      <td>202.094230</td>\n",
       "      <td>196.515703</td>\n",
       "      <td>181.847610</td>\n",
       "      <td>181.956953</td>\n",
       "      <td>184.744899</td>\n",
       "      <td>186.736011</td>\n",
       "      <td>6.832362</td>\n",
       "      <td>287.592425</td>\n",
       "      <td>287.269772</td>\n",
       "      <td>205.346176</td>\n",
       "      <td>285.715038</td>\n",
       "      <td>285.775379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pose_label                                    image_path  left_elbow_angle  \\\n",
       "0    Downdog  ../../data_clean/Downdog/Images/00000372.jpg        195.382277   \n",
       "1    Downdog  ../../data_clean/Downdog/Images/00000414.jpg        161.394529   \n",
       "2    Downdog  ../../data_clean/Downdog/Images/00000158.jpg        188.316559   \n",
       "3    Downdog  ../../data_clean/Downdog/Images/00000164.jpg        163.143669   \n",
       "4    Downdog  ../../data_clean/Downdog/Images/00000170.jpg        202.094230   \n",
       "\n",
       "   right_elbow_angle  left_shoulder_angle  right_shoulder_angle  \\\n",
       "0         189.994100           181.919382            180.159746   \n",
       "1         158.980446           163.869613            198.508847   \n",
       "2         189.387117           188.434129            168.625045   \n",
       "3         151.368673           174.269075            190.190288   \n",
       "4         196.515703           181.847610            181.956953   \n",
       "\n",
       "   left_knee_angle  right_knee_angle  hand_angle  left_hip_angle  \\\n",
       "0       153.536511        156.576545    1.285724      290.903067   \n",
       "1       181.839432        178.438866  358.240615       83.145803   \n",
       "2       186.825185        185.690404  342.449527      273.259646   \n",
       "3       180.294451        179.480325   29.600620       79.003156   \n",
       "4       184.744899        186.736011    6.832362      287.592425   \n",
       "\n",
       "   right_hip_angle  neck_angle_uk  left_wrist_angle_bk  right_wrist_angle_bk  \n",
       "0       287.620923     247.619865           275.332105            273.613412  \n",
       "1        85.550792     315.000000            80.704666             81.109078  \n",
       "2       275.749535     335.224859           278.820494            281.517431  \n",
       "3        74.516612      13.561052            79.992020             75.961132  \n",
       "4       287.269772     205.346176           285.715038            285.775379  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['pose_label', 'image_path', 'left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f\"{angles_path}/all_angles.csv\")\n",
    "print(\"all angles loaded\", \"shape:\", df_all.shape)\n",
    "display(df_all.head())\n",
    "print(\"Columns:\", list(df_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395e781",
   "metadata": {},
   "source": [
    "## 2. Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67e62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n",
      "Pose classes: ['Downdog', 'Goddess', 'Plank', 'Tree', 'Warrior2']\n",
      "Train/val/test sizes: 686 147 148\n"
     ]
    }
   ],
   "source": [
    "# build X, Y\n",
    "pose_col = \"pose_label\"\n",
    "non_feature_cols = [\"image_path\", pose_col]\n",
    "\n",
    "feature_cols = [c for c in df_all.columns if c not in non_feature_cols]\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "\n",
    "X = df_all[feature_cols].values.astype(np.float32)\n",
    "y_names = df_all[pose_col].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_names)\n",
    "class_names = list(le.classes_)\n",
    "print(\"Pose classes:\", class_names)\n",
    "\n",
    "# 70/15/15 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train/val/test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_ds = AngleDataset(X_train, y_train)\n",
    "val_ds = AngleDataset(X_val, y_val)\n",
    "test_ds = AngleDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9654b05",
   "metadata": {},
   "source": [
    "## 3. Train MLP\n",
    "\n",
    "TODO: residual MLP\n",
    "different parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# residual MLP model\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = out + x  # skip connection\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AngleResNet(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock(hidden_dim, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.input_layer(x)\n",
    "        h = self.blocks(h)\n",
    "        logits = self.head(h)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "in_dim = X.shape[1]\n",
    "num_classes = len(class_names)\n",
    "model = AngleResNet(in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "def run_epoch(loader, model, criterion, optimizer=None, device=\"cpu\"):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item()) * X_batch.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y_batch).sum().item()\n",
    "        total_samples += X_batch.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    acc = total_correct / total_samples\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return avg_loss, acc, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bcd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.254 acc=0.551 | val_loss=1.205 acc=0.517\n",
      "  ↳ New best model (val_acc=0.517)\n",
      "Epoch 02 | train_loss=0.630 acc=0.800 | val_loss=0.415 acc=0.884\n",
      "  ↳ New best model (val_acc=0.884)\n",
      "Epoch 03 | train_loss=0.320 acc=0.901 | val_loss=0.214 acc=0.946\n",
      "  ↳ New best model (val_acc=0.946)\n",
      "Epoch 04 | train_loss=0.254 acc=0.931 | val_loss=0.169 acc=0.952\n",
      "  ↳ New best model (val_acc=0.952)\n",
      "Epoch 05 | train_loss=0.168 acc=0.948 | val_loss=0.155 acc=0.959\n",
      "  ↳ New best model (val_acc=0.959)\n",
      "Epoch 06 | train_loss=0.166 acc=0.945 | val_loss=0.160 acc=0.952\n",
      "Epoch 07 | train_loss=0.110 acc=0.962 | val_loss=0.159 acc=0.959\n",
      "Epoch 08 | train_loss=0.103 acc=0.971 | val_loss=0.158 acc=0.966\n",
      "  ↳ New best model (val_acc=0.966)\n",
      "Epoch 09 | train_loss=0.086 acc=0.977 | val_loss=0.171 acc=0.966\n",
      "Epoch 10 | train_loss=0.108 acc=0.971 | val_loss=0.166 acc=0.973\n",
      "  ↳ New best model (val_acc=0.973)\n",
      "Epoch 11 | train_loss=0.108 acc=0.969 | val_loss=0.164 acc=0.973\n",
      "Epoch 12 | train_loss=0.096 acc=0.975 | val_loss=0.158 acc=0.973\n",
      "Epoch 13 | train_loss=0.095 acc=0.971 | val_loss=0.129 acc=0.973\n",
      "Epoch 14 | train_loss=0.073 acc=0.977 | val_loss=0.131 acc=0.973\n",
      "Epoch 15 | train_loss=0.079 acc=0.980 | val_loss=0.129 acc=0.973\n",
      "Epoch 16 | train_loss=0.053 acc=0.984 | val_loss=0.137 acc=0.966\n",
      "Epoch 17 | train_loss=0.056 acc=0.981 | val_loss=0.131 acc=0.973\n",
      "Epoch 18 | train_loss=0.081 acc=0.985 | val_loss=0.146 acc=0.973\n",
      "Epoch 19 | train_loss=0.071 acc=0.981 | val_loss=0.135 acc=0.973\n",
      "Epoch 20 | train_loss=0.059 acc=0.987 | val_loss=0.138 acc=0.973\n",
      "[EARLY STOP] No val improvement for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc, _, _ = run_epoch(\n",
    "        train_loader, model, criterion, optimizer, device=device\n",
    "    )\n",
    "    val_loss, val_acc, _, _ = run_epoch(\n",
    "        val_loader, model, criterion, optimizer=None, device=device\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.3f} acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.3f} acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ↳ New best model (val_acc={best_val_acc:.3f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[EARLY STOP] No val improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4431cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss=0.123 acc=0.980\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Downdog       1.00      1.00      1.00        29\n",
      "     Goddess       0.97      0.93      0.95        30\n",
      "       Plank       0.97      1.00      0.98        29\n",
      "        Tree       1.00      1.00      1.00        30\n",
      "    Warrior2       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.98       148\n",
      "   macro avg       0.98      0.98      0.98       148\n",
      "weighted avg       0.98      0.98      0.98       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_loss, test_acc, preds_test, targets_test = run_epoch(\n",
    "    test_loader, model, criterion, optimizer=None, device=device\n",
    ")\n",
    "print(f\"Test loss={test_loss:.3f} acc={test_acc:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets_test, preds_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757d441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: models/yoga_angle_resnet.pt\n",
      "Saved meta to: models/yoga_angle_resnet_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "# Per-pose angle stats using full dataset X, y\n",
    "angle_stats = {}\n",
    "for cls_idx, pose_name in enumerate(class_names):\n",
    "    mask = (y == cls_idx)\n",
    "    X_pose = X[mask]\n",
    "    mean_angles = X_pose.mean(axis=0)\n",
    "    std_angles  = X_pose.std(axis=0)\n",
    "    angle_stats[pose_name] = {\n",
    "        \"mean\": mean_angles,\n",
    "        \"std\": std_angles,\n",
    "    }\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "\n",
    "# save meta for inference/feedback\n",
    "meta = {\n",
    "    \"class_names\": class_names,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"angle_stats\": angle_stats,\n",
    "    \"hidden_dim\": 256,\n",
    "}\n",
    "with open(META_PATH, \"wb\") as f:\n",
    "    pickle.dump(meta, f)\n",
    "\n",
    "print(\"Saved meta to:\", META_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoga_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
