{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "RESULTS_DIR = \"angles/\"\n",
    "POSES = [\"downdog\", \"goddess\", \"plank\", \"tree\", \"warrior2\"]\n",
    "\n",
    "# model save paths\n",
    "MODELS_DIR = \"models/\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, \"yoga_angle_resnet.pt\")\n",
    "META_PATH  = os.path.join(MODELS_DIR, \"yoga_angle_resnet_meta.pkl\")\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 60\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "patience = 10 # for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033cfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all angles loaded shape: (981, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_label</th>\n",
       "      <th>image_path</th>\n",
       "      <th>left_elbow_angle</th>\n",
       "      <th>right_elbow_angle</th>\n",
       "      <th>left_shoulder_angle</th>\n",
       "      <th>right_shoulder_angle</th>\n",
       "      <th>left_knee_angle</th>\n",
       "      <th>right_knee_angle</th>\n",
       "      <th>angle_for_ardhaChandrasana1</th>\n",
       "      <th>angle_for_ardhaChandrasana2</th>\n",
       "      <th>hand_angle</th>\n",
       "      <th>left_hip_angle</th>\n",
       "      <th>right_hip_angle</th>\n",
       "      <th>neck_angle_uk</th>\n",
       "      <th>left_wrist_angle_bk</th>\n",
       "      <th>right_wrist_angle_bk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000000.jpg</td>\n",
       "      <td>193.939749</td>\n",
       "      <td>199.042214</td>\n",
       "      <td>183.262344</td>\n",
       "      <td>175.340034</td>\n",
       "      <td>186.249932</td>\n",
       "      <td>187.856616</td>\n",
       "      <td>358.892513</td>\n",
       "      <td>1.172412</td>\n",
       "      <td>359.486611</td>\n",
       "      <td>278.429215</td>\n",
       "      <td>277.825847</td>\n",
       "      <td>240.255119</td>\n",
       "      <td>279.715500</td>\n",
       "      <td>279.265069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000001.jpg</td>\n",
       "      <td>160.523425</td>\n",
       "      <td>165.983325</td>\n",
       "      <td>181.218875</td>\n",
       "      <td>178.150074</td>\n",
       "      <td>181.446741</td>\n",
       "      <td>185.428325</td>\n",
       "      <td>359.556523</td>\n",
       "      <td>0.409024</td>\n",
       "      <td>352.515241</td>\n",
       "      <td>86.378515</td>\n",
       "      <td>83.511490</td>\n",
       "      <td>178.781125</td>\n",
       "      <td>92.348562</td>\n",
       "      <td>90.218126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000002.jpg</td>\n",
       "      <td>168.929797</td>\n",
       "      <td>166.998650</td>\n",
       "      <td>169.650461</td>\n",
       "      <td>190.287842</td>\n",
       "      <td>171.887203</td>\n",
       "      <td>172.344633</td>\n",
       "      <td>0.281002</td>\n",
       "      <td>359.719951</td>\n",
       "      <td>9.370972</td>\n",
       "      <td>88.749626</td>\n",
       "      <td>86.819791</td>\n",
       "      <td>352.381454</td>\n",
       "      <td>82.517299</td>\n",
       "      <td>81.332269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000003.jpg</td>\n",
       "      <td>175.207966</td>\n",
       "      <td>173.291759</td>\n",
       "      <td>188.914927</td>\n",
       "      <td>170.921307</td>\n",
       "      <td>180.164934</td>\n",
       "      <td>180.759846</td>\n",
       "      <td>0.222692</td>\n",
       "      <td>359.770327</td>\n",
       "      <td>2.714021</td>\n",
       "      <td>70.659265</td>\n",
       "      <td>68.569748</td>\n",
       "      <td>33.896167</td>\n",
       "      <td>75.985298</td>\n",
       "      <td>75.006717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000004.jpg</td>\n",
       "      <td>196.852595</td>\n",
       "      <td>184.687954</td>\n",
       "      <td>194.188427</td>\n",
       "      <td>171.774849</td>\n",
       "      <td>187.427279</td>\n",
       "      <td>186.192317</td>\n",
       "      <td>358.967755</td>\n",
       "      <td>1.074590</td>\n",
       "      <td>2.256547</td>\n",
       "      <td>271.754788</td>\n",
       "      <td>270.489851</td>\n",
       "      <td>331.858399</td>\n",
       "      <td>278.549857</td>\n",
       "      <td>276.457471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pose_label                        image_path  left_elbow_angle  \\\n",
       "0    Downdog  data/Downdog/Images\\00000000.jpg        193.939749   \n",
       "1    Downdog  data/Downdog/Images\\00000001.jpg        160.523425   \n",
       "2    Downdog  data/Downdog/Images\\00000002.jpg        168.929797   \n",
       "3    Downdog  data/Downdog/Images\\00000003.jpg        175.207966   \n",
       "4    Downdog  data/Downdog/Images\\00000004.jpg        196.852595   \n",
       "\n",
       "   right_elbow_angle  left_shoulder_angle  right_shoulder_angle  \\\n",
       "0         199.042214           183.262344            175.340034   \n",
       "1         165.983325           181.218875            178.150074   \n",
       "2         166.998650           169.650461            190.287842   \n",
       "3         173.291759           188.914927            170.921307   \n",
       "4         184.687954           194.188427            171.774849   \n",
       "\n",
       "   left_knee_angle  right_knee_angle  angle_for_ardhaChandrasana1  \\\n",
       "0       186.249932        187.856616                   358.892513   \n",
       "1       181.446741        185.428325                   359.556523   \n",
       "2       171.887203        172.344633                     0.281002   \n",
       "3       180.164934        180.759846                     0.222692   \n",
       "4       187.427279        186.192317                   358.967755   \n",
       "\n",
       "   angle_for_ardhaChandrasana2  hand_angle  left_hip_angle  right_hip_angle  \\\n",
       "0                     1.172412  359.486611      278.429215       277.825847   \n",
       "1                     0.409024  352.515241       86.378515        83.511490   \n",
       "2                   359.719951    9.370972       88.749626        86.819791   \n",
       "3                   359.770327    2.714021       70.659265        68.569748   \n",
       "4                     1.074590    2.256547      271.754788       270.489851   \n",
       "\n",
       "   neck_angle_uk  left_wrist_angle_bk  right_wrist_angle_bk  \n",
       "0     240.255119           279.715500            279.265069  \n",
       "1     178.781125            92.348562             90.218126  \n",
       "2     352.381454            82.517299             81.332269  \n",
       "3      33.896167            75.985298             75.006717  \n",
       "4     331.858399           278.549857            276.457471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['pose_label', 'image_path', 'left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'angle_for_ardhaChandrasana1', 'angle_for_ardhaChandrasana2', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"angles/all_angles.csv\")\n",
    "print(\"all angles loaded\", \"shape:\", df_all.shape)\n",
    "display(df_all.head())\n",
    "print(\"Columns:\", list(df_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67e62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'angle_for_ardhaChandrasana1', 'angle_for_ardhaChandrasana2', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n",
      "Pose classes: ['Downdog', 'Goddess', 'Plank', 'Tree', 'Warrior2']\n",
      "Train/val/test sizes: 686 147 148\n"
     ]
    }
   ],
   "source": [
    "# build X, Y\n",
    "pose_col = \"pose_label\"\n",
    "non_feature_cols = [\"image_path\", pose_col]\n",
    "\n",
    "feature_cols = [c for c in df_all.columns if c not in non_feature_cols]\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "\n",
    "X = df_all[feature_cols].values.astype(np.float32)\n",
    "y_names = df_all[pose_col].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_names)\n",
    "class_names = list(le.classes_)\n",
    "print(\"Pose classes:\", class_names)\n",
    "\n",
    "# 70/15/15 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train/val/test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_ds = AngleDataset(X_train, y_train)\n",
    "val_ds = AngleDataset(X_val, y_val)\n",
    "test_ds = AngleDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6a0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# residual MLP model\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = out + x  # skip connection\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AngleResNet(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock(hidden_dim, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.input_layer(x)\n",
    "        h = self.blocks(h)\n",
    "        logits = self.head(h)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "in_dim = X.shape[1]\n",
    "num_classes = len(class_names)\n",
    "model = AngleResNet(in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "def run_epoch(loader, model, criterion, optimizer=None, device=\"cpu\"):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item()) * X_batch.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y_batch).sum().item()\n",
    "        total_samples += X_batch.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    acc = total_correct / total_samples\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return avg_loss, acc, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bcd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.259 acc=0.496 | val_loss=1.220 acc=0.429\n",
      "  ↳ New best model (val_acc=0.429)\n",
      "Epoch 02 | train_loss=0.641 acc=0.789 | val_loss=0.397 acc=0.884\n",
      "  ↳ New best model (val_acc=0.884)\n",
      "Epoch 03 | train_loss=0.377 acc=0.862 | val_loss=0.231 acc=0.946\n",
      "  ↳ New best model (val_acc=0.946)\n",
      "Epoch 04 | train_loss=0.277 acc=0.905 | val_loss=0.174 acc=0.959\n",
      "  ↳ New best model (val_acc=0.959)\n",
      "Epoch 05 | train_loss=0.202 acc=0.936 | val_loss=0.153 acc=0.973\n",
      "  ↳ New best model (val_acc=0.973)\n",
      "Epoch 06 | train_loss=0.208 acc=0.934 | val_loss=0.122 acc=0.973\n",
      "Epoch 07 | train_loss=0.166 acc=0.945 | val_loss=0.115 acc=0.966\n",
      "Epoch 08 | train_loss=0.116 acc=0.965 | val_loss=0.136 acc=0.973\n",
      "Epoch 09 | train_loss=0.109 acc=0.965 | val_loss=0.154 acc=0.973\n",
      "Epoch 10 | train_loss=0.119 acc=0.965 | val_loss=0.152 acc=0.966\n",
      "Epoch 11 | train_loss=0.104 acc=0.964 | val_loss=0.148 acc=0.966\n",
      "Epoch 12 | train_loss=0.086 acc=0.983 | val_loss=0.160 acc=0.959\n",
      "Epoch 13 | train_loss=0.082 acc=0.969 | val_loss=0.172 acc=0.966\n",
      "Epoch 14 | train_loss=0.114 acc=0.968 | val_loss=0.160 acc=0.966\n",
      "Epoch 15 | train_loss=0.073 acc=0.977 | val_loss=0.154 acc=0.966\n",
      "[EARLY STOP] No val improvement for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc, _, _ = run_epoch(\n",
    "        train_loader, model, criterion, optimizer, device=device\n",
    "    )\n",
    "    val_loss, val_acc, _, _ = run_epoch(\n",
    "        val_loader, model, criterion, optimizer=None, device=device\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.3f} acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.3f} acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ↳ New best model (val_acc={best_val_acc:.3f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[EARLY STOP] No val improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4431cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss=0.077 acc=0.986\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Downdog       1.00      1.00      1.00        29\n",
      "     Goddess       0.97      0.97      0.97        30\n",
      "       Plank       0.97      1.00      0.98        29\n",
      "        Tree       1.00      1.00      1.00        30\n",
      "    Warrior2       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.99       148\n",
      "   macro avg       0.99      0.99      0.99       148\n",
      "weighted avg       0.99      0.99      0.99       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_loss, test_acc, preds_test, targets_test = run_epoch(\n",
    "    test_loader, model, criterion, optimizer=None, device=device\n",
    ")\n",
    "print(f\"Test loss={test_loss:.3f} acc={test_acc:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets_test, preds_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: models/yoga_angle_resnet.pt\n",
      "Saved meta to: models/yoga_angle_resnet_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "# Per-pose angle stats using full dataset X, y\n",
    "angle_stats = {}\n",
    "for cls_idx, pose_name in enumerate(class_names):\n",
    "    mask = (y == cls_idx)\n",
    "    X_pose = X[mask]\n",
    "    mean_angles = X_pose.mean(axis=0)\n",
    "    std_angles  = X_pose.std(axis=0)\n",
    "    angle_stats[pose_name] = {\n",
    "        \"mean\": mean_angles,\n",
    "        \"std\": std_angles,\n",
    "    }\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "\n",
    "# save meta for inference/feedback\n",
    "meta = {\n",
    "    \"class_names\": class_names,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"angle_stats\": angle_stats,\n",
    "    \"hidden_dim\": 256,\n",
    "}\n",
    "with open(META_PATH, \"wb\") as f:\n",
    "    pickle.dump(meta, f)\n",
    "\n",
    "print(\"Saved meta to:\", META_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
