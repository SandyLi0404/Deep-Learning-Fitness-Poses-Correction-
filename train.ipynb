{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7e4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "RESULTS_DIR = \"angles/\"\n",
    "POSES = [\"downdog\", \"goddess\", \"plank\", \"tree\", \"warrior2\"]\n",
    "\n",
    "# model save paths\n",
    "MODELS_DIR = \"models/\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, \"yoga_angle_resnet.pt\")\n",
    "META_PATH  = os.path.join(MODELS_DIR, \"yoga_angle_resnet_meta.pkl\")\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 60\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "patience = 10 # for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "033cfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all angles loaded shape: (981, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_label</th>\n",
       "      <th>image_path</th>\n",
       "      <th>left_elbow_angle</th>\n",
       "      <th>right_elbow_angle</th>\n",
       "      <th>left_shoulder_angle</th>\n",
       "      <th>right_shoulder_angle</th>\n",
       "      <th>left_knee_angle</th>\n",
       "      <th>right_knee_angle</th>\n",
       "      <th>hand_angle</th>\n",
       "      <th>left_hip_angle</th>\n",
       "      <th>right_hip_angle</th>\n",
       "      <th>neck_angle_uk</th>\n",
       "      <th>left_wrist_angle_bk</th>\n",
       "      <th>right_wrist_angle_bk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000000.jpg</td>\n",
       "      <td>193.939749</td>\n",
       "      <td>199.042214</td>\n",
       "      <td>183.262344</td>\n",
       "      <td>175.340034</td>\n",
       "      <td>186.249932</td>\n",
       "      <td>187.856616</td>\n",
       "      <td>359.486611</td>\n",
       "      <td>278.429215</td>\n",
       "      <td>277.825847</td>\n",
       "      <td>240.255119</td>\n",
       "      <td>279.715500</td>\n",
       "      <td>279.265069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000001.jpg</td>\n",
       "      <td>160.523425</td>\n",
       "      <td>165.983325</td>\n",
       "      <td>181.218875</td>\n",
       "      <td>178.150074</td>\n",
       "      <td>181.446741</td>\n",
       "      <td>185.428325</td>\n",
       "      <td>352.515241</td>\n",
       "      <td>86.378515</td>\n",
       "      <td>83.511490</td>\n",
       "      <td>178.781125</td>\n",
       "      <td>92.348562</td>\n",
       "      <td>90.218126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000002.jpg</td>\n",
       "      <td>168.929797</td>\n",
       "      <td>166.998650</td>\n",
       "      <td>169.650461</td>\n",
       "      <td>190.287842</td>\n",
       "      <td>171.887203</td>\n",
       "      <td>172.344633</td>\n",
       "      <td>9.370972</td>\n",
       "      <td>88.749626</td>\n",
       "      <td>86.819791</td>\n",
       "      <td>352.381454</td>\n",
       "      <td>82.517299</td>\n",
       "      <td>81.332269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000003.jpg</td>\n",
       "      <td>175.207966</td>\n",
       "      <td>173.291759</td>\n",
       "      <td>188.914927</td>\n",
       "      <td>170.921307</td>\n",
       "      <td>180.164934</td>\n",
       "      <td>180.759846</td>\n",
       "      <td>2.714021</td>\n",
       "      <td>70.659265</td>\n",
       "      <td>68.569748</td>\n",
       "      <td>33.896167</td>\n",
       "      <td>75.985298</td>\n",
       "      <td>75.006717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downdog</td>\n",
       "      <td>data/Downdog/Images\\00000004.jpg</td>\n",
       "      <td>196.852595</td>\n",
       "      <td>184.687954</td>\n",
       "      <td>194.188427</td>\n",
       "      <td>171.774849</td>\n",
       "      <td>187.427279</td>\n",
       "      <td>186.192317</td>\n",
       "      <td>2.256547</td>\n",
       "      <td>271.754788</td>\n",
       "      <td>270.489851</td>\n",
       "      <td>331.858399</td>\n",
       "      <td>278.549857</td>\n",
       "      <td>276.457471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pose_label                        image_path  left_elbow_angle  \\\n",
       "0    Downdog  data/Downdog/Images\\00000000.jpg        193.939749   \n",
       "1    Downdog  data/Downdog/Images\\00000001.jpg        160.523425   \n",
       "2    Downdog  data/Downdog/Images\\00000002.jpg        168.929797   \n",
       "3    Downdog  data/Downdog/Images\\00000003.jpg        175.207966   \n",
       "4    Downdog  data/Downdog/Images\\00000004.jpg        196.852595   \n",
       "\n",
       "   right_elbow_angle  left_shoulder_angle  right_shoulder_angle  \\\n",
       "0         199.042214           183.262344            175.340034   \n",
       "1         165.983325           181.218875            178.150074   \n",
       "2         166.998650           169.650461            190.287842   \n",
       "3         173.291759           188.914927            170.921307   \n",
       "4         184.687954           194.188427            171.774849   \n",
       "\n",
       "   left_knee_angle  right_knee_angle  hand_angle  left_hip_angle  \\\n",
       "0       186.249932        187.856616  359.486611      278.429215   \n",
       "1       181.446741        185.428325  352.515241       86.378515   \n",
       "2       171.887203        172.344633    9.370972       88.749626   \n",
       "3       180.164934        180.759846    2.714021       70.659265   \n",
       "4       187.427279        186.192317    2.256547      271.754788   \n",
       "\n",
       "   right_hip_angle  neck_angle_uk  left_wrist_angle_bk  right_wrist_angle_bk  \n",
       "0       277.825847     240.255119           279.715500            279.265069  \n",
       "1        83.511490     178.781125            92.348562             90.218126  \n",
       "2        86.819791     352.381454            82.517299             81.332269  \n",
       "3        68.569748      33.896167            75.985298             75.006717  \n",
       "4       270.489851     331.858399           278.549857            276.457471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['pose_label', 'image_path', 'left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"angles/all_angles.csv\")\n",
    "print(\"all angles loaded\", \"shape:\", df_all.shape)\n",
    "display(df_all.head())\n",
    "print(\"Columns:\", list(df_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67e62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['left_elbow_angle', 'right_elbow_angle', 'left_shoulder_angle', 'right_shoulder_angle', 'left_knee_angle', 'right_knee_angle', 'hand_angle', 'left_hip_angle', 'right_hip_angle', 'neck_angle_uk', 'left_wrist_angle_bk', 'right_wrist_angle_bk']\n",
      "Pose classes: ['Downdog', 'Goddess', 'Plank', 'Tree', 'Warrior2']\n",
      "Train/val/test sizes: 686 147 148\n"
     ]
    }
   ],
   "source": [
    "# build X, Y\n",
    "pose_col = \"pose_label\"\n",
    "non_feature_cols = [\"image_path\", pose_col]\n",
    "\n",
    "feature_cols = [c for c in df_all.columns if c not in non_feature_cols]\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "\n",
    "X = df_all[feature_cols].values.astype(np.float32)\n",
    "y_names = df_all[pose_col].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_names)\n",
    "class_names = list(le.classes_)\n",
    "print(\"Pose classes:\", class_names)\n",
    "\n",
    "# 70/15/15 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train/val/test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_ds = AngleDataset(X_train, y_train)\n",
    "val_ds = AngleDataset(X_val, y_val)\n",
    "test_ds = AngleDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d6a0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# residual MLP model\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = out + x  # skip connection\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AngleResNet(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock(hidden_dim, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.input_layer(x)\n",
    "        h = self.blocks(h)\n",
    "        logits = self.head(h)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "in_dim = X.shape[1]\n",
    "num_classes = len(class_names)\n",
    "model = AngleResNet(in_dim, num_classes, hidden_dim=256, num_blocks=3, dropout=0.5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "def run_epoch(loader, model, criterion, optimizer=None, device=\"cpu\"):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item()) * X_batch.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y_batch).sum().item()\n",
    "        total_samples += X_batch.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    acc = total_correct / total_samples\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return avg_loss, acc, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bcd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.254 acc=0.551 | val_loss=1.205 acc=0.517\n",
      "  ↳ New best model (val_acc=0.517)\n",
      "Epoch 02 | train_loss=0.630 acc=0.800 | val_loss=0.415 acc=0.884\n",
      "  ↳ New best model (val_acc=0.884)\n",
      "Epoch 03 | train_loss=0.320 acc=0.901 | val_loss=0.214 acc=0.946\n",
      "  ↳ New best model (val_acc=0.946)\n",
      "Epoch 04 | train_loss=0.254 acc=0.931 | val_loss=0.169 acc=0.952\n",
      "  ↳ New best model (val_acc=0.952)\n",
      "Epoch 05 | train_loss=0.168 acc=0.948 | val_loss=0.155 acc=0.959\n",
      "  ↳ New best model (val_acc=0.959)\n",
      "Epoch 06 | train_loss=0.166 acc=0.945 | val_loss=0.160 acc=0.952\n",
      "Epoch 07 | train_loss=0.110 acc=0.962 | val_loss=0.159 acc=0.959\n",
      "Epoch 08 | train_loss=0.103 acc=0.971 | val_loss=0.158 acc=0.966\n",
      "  ↳ New best model (val_acc=0.966)\n",
      "Epoch 09 | train_loss=0.086 acc=0.977 | val_loss=0.171 acc=0.966\n",
      "Epoch 10 | train_loss=0.108 acc=0.971 | val_loss=0.166 acc=0.973\n",
      "  ↳ New best model (val_acc=0.973)\n",
      "Epoch 11 | train_loss=0.108 acc=0.969 | val_loss=0.164 acc=0.973\n",
      "Epoch 12 | train_loss=0.096 acc=0.975 | val_loss=0.158 acc=0.973\n",
      "Epoch 13 | train_loss=0.095 acc=0.971 | val_loss=0.129 acc=0.973\n",
      "Epoch 14 | train_loss=0.073 acc=0.977 | val_loss=0.131 acc=0.973\n",
      "Epoch 15 | train_loss=0.079 acc=0.980 | val_loss=0.129 acc=0.973\n",
      "Epoch 16 | train_loss=0.053 acc=0.984 | val_loss=0.137 acc=0.966\n",
      "Epoch 17 | train_loss=0.056 acc=0.981 | val_loss=0.131 acc=0.973\n",
      "Epoch 18 | train_loss=0.081 acc=0.985 | val_loss=0.146 acc=0.973\n",
      "Epoch 19 | train_loss=0.071 acc=0.981 | val_loss=0.135 acc=0.973\n",
      "Epoch 20 | train_loss=0.059 acc=0.987 | val_loss=0.138 acc=0.973\n",
      "[EARLY STOP] No val improvement for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc, _, _ = run_epoch(\n",
    "        train_loader, model, criterion, optimizer, device=device\n",
    "    )\n",
    "    val_loss, val_acc, _, _ = run_epoch(\n",
    "        val_loader, model, criterion, optimizer=None, device=device\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.3f} acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.3f} acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  ↳ New best model (val_acc={best_val_acc:.3f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[EARLY STOP] No val improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4431cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss=0.123 acc=0.980\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Downdog       1.00      1.00      1.00        29\n",
      "     Goddess       0.97      0.93      0.95        30\n",
      "       Plank       0.97      1.00      0.98        29\n",
      "        Tree       1.00      1.00      1.00        30\n",
      "    Warrior2       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.98       148\n",
      "   macro avg       0.98      0.98      0.98       148\n",
      "weighted avg       0.98      0.98      0.98       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_loss, test_acc, preds_test, targets_test = run_epoch(\n",
    "    test_loader, model, criterion, optimizer=None, device=device\n",
    ")\n",
    "print(f\"Test loss={test_loss:.3f} acc={test_acc:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets_test, preds_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757d441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: models/yoga_angle_resnet.pt\n",
      "Saved meta to: models/yoga_angle_resnet_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "# Per-pose angle stats using full dataset X, y\n",
    "angle_stats = {}\n",
    "for cls_idx, pose_name in enumerate(class_names):\n",
    "    mask = (y == cls_idx)\n",
    "    X_pose = X[mask]\n",
    "    mean_angles = X_pose.mean(axis=0)\n",
    "    std_angles  = X_pose.std(axis=0)\n",
    "    angle_stats[pose_name] = {\n",
    "        \"mean\": mean_angles,\n",
    "        \"std\": std_angles,\n",
    "    }\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "\n",
    "# save meta for inference/feedback\n",
    "meta = {\n",
    "    \"class_names\": class_names,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"angle_stats\": angle_stats,\n",
    "    \"hidden_dim\": 256,\n",
    "}\n",
    "with open(META_PATH, \"wb\") as f:\n",
    "    pickle.dump(meta, f)\n",
    "\n",
    "print(\"Saved meta to:\", META_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
